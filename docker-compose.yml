version: '3.8'

services:
  localai:
    image: ghcr.io/davidgibbons/localai-strix:3.9.0
    container_name: localai
    ports:
      - "8080:8080"
    environment:
      - DEBUG=true
      # You might need to specify the backend or other flags depending on the usage
    volumes:
      - ./models:/models
      - ./backends:/backends
      - ./config:/configuration
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    restart: unless-stopped
    # Depending on the base image user, we might need to set 'user: root' or add the user to 'render' group
    # but the base image likely handles this for the 'toolbox' user or defaults to root.
